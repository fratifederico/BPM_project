# Business_project
Project of Business and project management, A.Y. 2022-23

## Introduction:
Welcome to the presentation of our business project on generative AI for user guide generation. In this project, we explored the potential of using generative AI to automatically generate comprehensive and informative user guides from product specifications. Our main objective was to investigate the capabilities and limitations of generative AI in handling complex specifications and streamlining the user guide creation process.

## Objective:
Our project aimed to answer the fundamental question: Can generative AI be harnessed to generate high-quality user guides solely based on product specifications? We wanted to understand the level of complexity that can be effectively handled by the AI model and explore its practical applications in documentation processes.

## Methodology:
To achieve our objective, we employed the generative AI model GPT 3.5 Turbo. We designed several Python scripts to study the behavior of generative AI in developing user guides. These scripts utilized data preprocessing techniques to prepare the product specifications for input into the AI model.

## Validation Metrics:
Throughout the project, we employed various validation metrics to assess the quality and accuracy of the generated user guides. These metrics allowed us to evaluate the performance of our generative AI-based solution. Here are the validation metrics we used:

NLP-based similarity verification:

We utilized natural language processing (NLP) techniques to measure the similarity between the generated user guides and existing real user guides.
This metric helped us assess how accurately our system could produce guides that reflected the characteristics and information present in the existing guides.
Length comparison:

To verify the length of the generated guides, we used an NLP library to count the number of words used.
This comparison helped us determine if the generated guides were generally as long as the real ones or not.
Keyword comparison:

We conducted a comparison of keywords between the generated user guides and the real user guides.
This comparison ensured that the most frequently used words in both sets of documents were consistent, evaluating the correctness and relevance of the language generated by our system.
Human evaluation:

We performed a thorough evaluation of the generated user guides, assessing their clarity, completeness, and usefulness.
Our team carefully analyzed the content and provided feedback on the overall quality.
